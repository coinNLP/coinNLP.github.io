<!DOCTYPE html>
<html lang="en">

<head>
<title>COIN: COmmonsense INference in Natural Language Processing</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- Prevent caching -->
<META HTTP-EQUIV="Pragma" CONTENT="no-cache">
<META HTTP-EQUIV="Expires" CONTENT="-1">
<link href="bootstrap/css/bootstrap.min.css" rel="stylesheet" media="screen">

<style>
/* Customize container */
@media (min-width: 968px) {
  .container {
    max-width: 968px;
  }
}
.container-narrow > hr {
  margin: 30px 0;
}
/* Customize dropdown menu */
.dropdown {
 cursor: pointer;
}
.dropdown sup {
 color: rgb(66, 139, 202);
}
.dropdown sup:hover, .dropdown sup:focus {
    color: rgb(42, 100, 150);
    text-decoration: underline;
}
.dropdown-menu {
  min-width: 500px;
  left: -200px;
}
.dropdown-menu li {
  margin-bottom: .5em;
  /*border-top-style:solid; padding-left:10px;*/
}

ol.answers {
  padding-top: 0;
  margin-bottom: 1em;
}

.task-example {
  border: 2px solid #ccc;
  padding: 1em;
  margin: 1em;
}

.ent {
  font-weight: bold;
  color: #686;
}

</style>
</head>

<body data-spy="scroll" data-target="#navbar" data-offset="70" onload="load()">

    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">COIN</a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="#speakers">Invited Speakers</a></li>
	    <li><a href="#program">Program</a></li>
            <!--li><a href="#call">Call</a></li-->
            <li><a href="#task">Shared Tasks</a></li>
            <!--li><a href="#leaderboards">Leaderboards</a></li-->
            <!--li><a href="#dates">Dates</a></li-->
            <li><a href="#organizers">Organizers &amp; Committee</a></li>
           </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="https://www.emnlp-ijcnlp2019.org/">EMNLP-IJCNLP 2019</a></li>
            <!--li><a href="../navbar-static-top/">Static top</a></li-->
            <!--li class="active"><a href="./">Fixed top</a></li-->
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

<br/>
<br/>

<br/>
<center><h2 id="top"><b>COIN: COmmonsense INference in Natural Language Processing</b></h2></center>
<center><h4>Workshop to be held in conjunction with EMNLP-IJCNLP in Hong Kong</h4></center>
<center><h4>November 3, 2019</h4></center>
<br/>

<br/>
<div class="alert alert-success" role="alert">
<strong>Update: </strong>We are excited to announce the full workshop program, which you can view <a href="#program">here</a>
</div>

<p>Research in natural language understanding and textual inference has advanced considerably in recent years, resulting in powerful models that are able to read and understand texts, even outperforming humans in some cases. However, it remains challenging to answer questions that go beyond the texts themselves, requiring the use of additional commonsense knowledge. Previous work has explored using both explicit representations of background knowledge (e.g., <a href="http://conceptnet.io/">ConceptNet</a> or <a href="http://rtw.ml.cmu.edu/rtw/">NELL</a>), and latent representations that capture some aspects of commonsense (e.g., <a href="https://blog.openai.com/language-unsupervised/">OpenAI GPT</a>). These and any other methods for representing and using commonsense in NLP are of interest to this workshop.</p>

<p>The COIN workshop aims at bringing together researchers that are interested in modeling commonsense knowledge, developing computational models thereof, and applying commonsense inference methods in NLP tasks. We are interested in any type of commonsense knowledge representation, and explicitly encourage work that makes use of knowledge bases and approaches developed to mine or learn commonsense from other sources. The workshop is also open for evaluation proposals that explore new ways of evaluating methods of commonsense inference, going beyond established natural language processing tasks.</p>

<p>The workshop will also include two shared tasks on common-sense machine reading comprehension in English, one based on everyday scenarios and one based on news events. See <a href="#task">Shared Tasks</a> for more details.</p>

<div class="page-header">
  <h1>Mailing list</h1>
</div>

<p>If you are participating or interested in participating in COIN, we welcome you
  to join the <a href="https://groups.google.com/forum/#!forum/coin-participants">
    COIN mailing list</a> on Google Groups. Follow the link and click "Join Group"
  to join.</p>

<a name="speakers"></a>
<div class="page-header">
  <h1>Invited Speakers</h1>
</div>

<ul>
<li><p><h4><a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>: <strong>Commonsense Intelligence: Cracking the Longstanding Challenge in AI</strong></h4></p>
<p>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#yejinabs" aria-expanded="false" aria-controls="collapseExample">
    Abstract
  </button>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#yejinbio" aria-expanded="false" aria-controls="collapseExample">
    Bio
  </button>
</p>
<div class="collapse" id="yejinabs">
  <div class="card card-body">
    <p>Despite considerable advances in deep learning, AI remains to be narrow and brittle. One fundamental limitation comes from its lack of commonsense intelligence: reasoning about everyday situations and events, which in turn, requires knowledge about how the physical and social world works. In this talk, I will share some of our recent efforts that attempt to crack commonsense intelligence. </p>
    <p>
    First, I will introduce ATOMIC, the atlas of everyday commonsense knowledge and reasoning, organized as a graph of 877k if-then rules (e.g., &ldquo;if X pays Y a compliment, then Y will likely return the compliment&rdquo;). Next, I will introduce COMET, our deep neural networks that can learn from and generalize beyond the ATOMIC commonsense graph. Finally, I will present RAINBOW, a collection of seven benchmarks that aims to cover a wide spectrum of commonsense intelligence from natural language inference to adductive reasoning to visual commonsense reasoning. I will conclude the talk by discussing major open research questions, including the importance of algorithmic solutions to reduce incidental biases in data that can lead to overestimation of true AI capabilities.</p>
  </div>
</div>
<div class="collapse" id="yejinbio">
  <div class="card card-body">
    Yejin Choi is an associate professor at the Paul G. Allen School of Computer Science & Engineering at the University of Washington and also a senior research manager at AI2  overseeing the project Mosaic. Her research interests include language grounding with vision, physical and social commonsense knowledge, language generation with long-term coherence, conversational AI, and AI for social good. She was a recepient of Borg Early Career Award (BECA) in 2018, among the IEEE’s AI Top 10 to Watch in 2015, a co-recipient of the Marr Prize at ICCV 2013, and a faculty advisor for the Sounding Board team that won the inaugural Alexa Prize Challenge in 2017.  Her work on detecting deceptive reviews, predicting the literary success, and interpreting bias and connotation has been featured by numerous media outlets including NBC News for New York, NPR Radio, New York Times, and Bloomberg Business Week. She received her Ph.D. in Computer Science from Cornell University.
  </div>
</div>
</li>
<li><p><h4><a href="http://www.science.auckland.ac.nz/people/profile/m-witbrock">Michael Witbrock</a>: <strong>Learning to Reason: from Question Answering to Problem Solving 

</strong></h4></p>
<p>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#michaelabs" aria-expanded="false" aria-controls="collapseExample">
    Abstract
  </button>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#michaelbio" aria-expanded="false" aria-controls="collapseExample">
    Bio
  </button>
</p>
<div class="collapse" id="michaelabs">
  <div class="card card-body">
    Recent advances in Machine Learning applied to Natural Language Processing have resulted in systems with quite impressive scores on Question-Answering tests in text and simple visual domains. Similarly, Google Assistant and other similar systems are performing quite well in answering real questions by answer extraction. This progress is real, but it is limited in some important respects: the systems typically have worked by identifying a passage span to serve as an answer; more recently, in &ldquo;Multi-hop&rdquo; QA, they have started to work by forming a short linear chain of extracted relations from question to answer.  This falls significantly short of human-problem solving, including question-answering: it does not recursively decompose problems for solution, it does not follow that decomposition to assemble answers, and it does not store and apply salient background knowledge for decomposition, partial solution, or answer composition.  Although it's at the early stage, the aim of our Broad AI Lab is to learn from the far-from-general capabilities of symbolic AI to  extend our reach, especially in problem-solving over text, by applying learning to bridge these current short-falls. In this talk , I'll try to characterise the problem-solving problem and the baseline state-of-the-art, describe some preliminary previous work done with the Learning to Reason team at IBM Research, and sketch a programme towards broader, learning-based, quasi-symbolic AI. We hope this programme will extend the reach of AI-based problem solving, and especially question-answering.
  </div>
</div>
<div class="collapse" id="michaelbio">
  <div class="card card-body">
    Michael Witbrock is a professor of computer science at The University of Auckland, building a research group, the Broad AI Lab, integrating machine learning, reasoning and natural language understanding, with an additional focus on maximizing the near-term benefit of AI to NZ entrepreneurs and business, and more generally achieving the best social and civilizational impacts of increasingly powerful AI.  Prof. Witbrock's PhD is in Computer Science from Carnegie Mellon, and he holds a BSc(Hons) in Psychology from Otago. Before joining the University, he was a Distinguished Research Staff Member and manager of the Reasoning group at IBM T J Watson Research Center in Yorktown Heights, NY.
  </div>
</div>
</li>
</ul>


<a name="program"></a>
<div class="page-header">
  <h1>Workshop Program</h1>
  
<table class="table table-striped">
  <tbody>
    <tr>
      <td>9:00</td>
      <td>Opening</td>
    </tr>
    <tr>
      <td class="info">9:10</td>
      <td>
        <b>Invited talk</b><br/>
	Commonsense Intelligence---Cracking the Longstanding Challenge in AI <sup> <a href="https://www.dropbox.com/s/jdnyp8oy6c91vvq/ttic.pdf?dl=0">[PDF]</a></sup><br/>
        <i>Yejin Choi</i></td>
    </tr>
    <tr>
      <td class="success">10:10</td>
      <td>
	Understanding Commonsense Inference Aptitude of Deep Contextual Representations
	<br/><i>Jeff Da and Jungo Kasai</i>
      </td>
    </tr>
    <tr>
      <td>10:30</td>
      <td><strong>Coffee break</strong></td>
    </tr>
    <tr>
      <td class="success">11:00</td>
      <td>A Hybrid Neural Network Model for Commonsense Reasoning
	<br/><i>Pengcheng He, Xiaodong Liu, Weizhu Chen, Jianfeng Gao</i>
      </td>
    </tr>
    <tr>
      <td class="success">11:20</td>
      <td>Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering
	<br/><i>Kaixin Ma, Jonathan Francis, Quanyang Lu, Eric Nyberg, Alessandro Oltramari</i>
      </td>
    </tr>
    <tr>
      <td class="success">11:40</td>
      <td>When Choosing Plausible Alternatives, Clever Hans can be Clever
	<br/><i>Pride Kavumba, Naoya Inoue, Benjamin Heinzerling, Keshav Singh, Paul Reisert, Kentaro Inui</i>
      </td>
    </tr>
    <tr>
      <td class="success">12:00</td>
      <td>Commonsense about Human Senses: Labeled Data Collection Processes
	<br/><i>Ndapa Nakashole</i>
      </td>
    </tr>
    <tr>
      <td>12:20</td>
      <td><strong>Lunch break</strong></td>
    </tr>
    <tr>
      <td class="info">14:00</td>
      <td>
	<b>Invited talk</b><br/>
	Learning to Reason: from Question Answering to Problem Solving <sup> <a href="witbrock.pdf">[PDF]</a></sup></br>
	<i>Michael Witbrock</i></td>
    </tr>
    <tr>
      <td class="success">15:00</td>
      <td>
	Extracting Common Inference Patterns from Semi-Structured Explanations
	<br/><i>Sebastian Thiem and Peter Jansen</i>
      </td>
    </tr>
    <tr>
      <td class="info">15:20</td>
      <td><b>Poster session &amp; coffee break </b><br/></td>
    </tr>    
    <tr>
      <td class="info"></td><td>Commonsense Inference in Natural Language Processing (COIN) - Shared Task Report
	<br/><i>Simon Ostermann, Sheng Zhang, Michael Roth, Peter Clark</i></td></tr>
    <tr>
      <td class="info"></td><td>KARNA at COIN Shared Task 1: Bidirectional Encoder Representations from Transformers with relational knowledge for machine comprehension with common sense
	<br/><i>Yash Jain and Chinmay Singh</i></td></tr>
    <tr>
      <td class="info"></td><td>IIT-KGP at COIN 2019: Using pre-trained Language Models for modeling Machine Comprehension
	<br/><i>Prakhar Sharma and Sumegh Roychowdhury</i></td></tr>
    <tr>
      <td class="info"></td><td>Jeff Da at COIN - Shared Task
	<br/><i>Jeff Da</i></td></tr>
    <tr>
      <td class="info"></td><td>Pingan Smart Health and SJTU at COIN - Shared Task: utilizing Pre-trained Language Models and Common-sense Knowledge in Machine Reading Tasks
	<br/><i>Xiepeng Li, Zhexi Zhang, Wei Zhu, Zheng Li, Yuan Ni, Peng Gao, Junchi Yan, Guotong Xie</i></td></tr>
    <tr>
      <td class="info"></td><td>BLCU-NLP at COIN-Shared Task1: Stagewise Fine-tuning BERT for Commonsense Inference in Everyday Narrations
	<br/><i>Chunhua Liu and Dong Yu</i></td></tr>
    <tr>
      <td class="success">16:20</td>
      <td>
	Commonsense inference in human-robot communication
	<br/><i>Aliaksandr Huminski, Yan Bin Ng, Kenneth Kwok, Francis Bond</i>
      </td>
    </tr>
    <tr>
      <td class="success">16:40</td>
      <td>
	Diversity-aware Event Prediction based on a Conditional Variational Autoencoder with Reconstruction
	<br/><i>Hirokazu Kiyomaru, Kazumasa Omura, Yugo Murawaki, Daisuke Kawahara, Sadao Kurohashi</i>
      </td>
    </tr>
    <tr>
      <td class="success">17:00</td>
      <td>
	Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text
	<br/><i>Ian Porada, Kaheer Suleman, Jackie Chi Kit Cheung</i>
      </td>
    </tr>
    <tr>
      <td class="success">17:15</td>
      <td>
	How Pre-trained Word Representations Capture Commonsense Physical Comparisons
	<br/><i>Pranav Goel, Shi Feng, Jordan Boyd-Graber</i>
      </td>
    </tr>
  </tbody>
</table>
</div>

<!--a name="call"></a>
<div class="page-header">
  <h1>Call for Submissions</h1>
</div>
<p>We invite both long (8 pages) and short (4 page) papers. The limits refer to
the content and any number of additional pages for references are allowed. The
papers should follow the EMNLP-IJCNLP 2019 formatting instructions.</p>

<p>Each submission must be anonymized, written in English, and contain a title and
abstract. We especially welcome the following types of papers:</p>

<ul>
<li>Technical papers that demonstrate the impact of commonsense knowledge inference in tasks and applications</li>
<li>Position papers that reflect innovative, creative and thought-provoking ideas</li>
<li>Theoretical papers that advance our understanding of commonsense inference</li>
<li>Papers that describe data collection efforts for evaluating commonsense inference</li>
<li>Survey papers that review the current state of research in a specific area</li>
<li>Papers describing submissions to the shared tasks described below</li>
</ul>

<p>Please submit your papers at <a href="https://www.softconf.com/emnlp2019/ws-COIN">https://www.softconf.com/emnlp2019/ws-COIN</a></p-->


<a name="task"></a>
<div class="page-header">
  <h1>Shared Tasks</h1>
</div>

<p>This workshop includes two shared tasks on English reading comprehension using commonsense knowledge. The first task is a multiple choice reading comprehension task on everyday narrations. The second task is a cloze task on news texts. </p>

<p>In contrast to other machine comprehension tasks and workshops, our focus will be on the inferences over commonsense knowledge about events and participants that are required for text understanding. Participants are encouraged to use any external resources that could improve their systems. Below we give a list of external resources that we expect to be helpful for the tasks.</p>

<p>If you make submissions to one of the shared tasks, they will be added to the development data leaderboard. The test data for both tasks will not be public, but you will have to submit your models so that we can run them on the test data. During the evaluation pahse (first 3 weeks of June), your submissions will count towards the final ranking on the test data. The final leaderboard will be made public only after the evaluation phase ends.</p>

<p>The development set leaderboard will be updated approx. once a week with all current submissions.</p>

<p><b>If you want to participate or have any questions, please join the <a href="https://groups.google.com/forum/#!forum/coin-participants">google group</a> for participants. We'll post updates in the group, and answer questions on the shared task and workshop.</b></p>

<h3><a href="task1.html">Shared Task 1: Commonsense inference in everyday narrations</a></h3>

<h3><a href="task2.html">Shared Task 2: Commonsense inference in news articles</a></h3>

<h3>Commonsense Knowledge Resources</h3>

<h4>Commonsense Knowledge Bases</h4>
<ul>
  <li>ConceptNet [<a href="http://lrec-conf.org/proceedings/lrec2012/pdf/1072_Paper.pdf">paper</a>|<a href="https://www.http://conceptnet.io/">data</a>]</li>
  <li>WebChild [<a href="http://people.mpi-inf.mpg.de/~ntandon/papers/tandon-acl2017-demo.pdf">paper</a>|<a href="https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/webchild/">web</a>]</li>
  <li>NELL [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/10049/9557">paper</a>|<a href="http://rtw.ml.cmu.edu/rtw/">web</a>]</li>
  <li>ATOMIC [<a href="https://homes.cs.washington.edu/~msap/atomic/data/sap2019atomic.pdf">paper</a>|<a href="https://homes.cs.washington.edu/~msap/atomic/">web</a>]</li>
  <li>ACL list of RTE Knowledge Resources [<a href="https://aclweb.org/aclwiki/RTE_Knowledge_Resources">web</a>]</li>
</ul>

<h4>Script Knowledge Bases</h4>
<ul>
  <li>DeScript [<a href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/913_Paper.pdf">paper</a>|<a href="https://www.hidrive.strato.com/lnk/osATHAmv">data</a>]</li>
  <li>RKP&nbsp;[<a href="http://www.coli.uni-saarland.de/projects/smile/docs/scripts-10.pdf">paper</a>|<a href="http://www.coli.uni-saarland.de/projects/smile/page.php?id=software">data</a>]</li>
  <li>OMCS stories [<a href="http://web.media.mit.edu/~lieber/Teaching/Common-Sense-Course-02/Open-Mind-AAAI2002.pdf">paper</a>|<a href="https://www.hidrive.strato.com/lnk/bqSpUvas">data</a>|<a href="https://www.media.mit.edu/research/groups/5994/open-mind-common-sense">web</a>]</li>
</ul>
<h4>Script Knowledge Representations</h4>
<ul>
  <li>narrative chains&nbsp;[<a href="https://nlp.stanford.edu/pubs/narrative-chains08.pdf">paper1</a>&nbsp;<a href="http://aclweb.org/anthology/P/P09/P09-1068.pdf">paper2</a>|<a href="https://www.usna.edu/Users/cs/nchamber/data/schemas/acl09/">data</a>]</li>
  <li>event embeddings [<a href="http://aclweb.org/anthology/W14-1606">paper</a>]</li>
  <li>event paraphrase sets [<a href="http://www.aclweb.org/anthology/W/W17/W17-09.pdf#page=13">paper</a>]</li>
</ul>

<a name="dates"></a>
<div class="page-header">
  <h1>Important Dates</h1>
</div>
<ul>
  <li>Late March 2019: Release of shared-task training data</li>
  <li>May 10, 2019: First call for workshop papers</li>
  <li>June 14, 2019: Beginning of evaluation phase for the shared tasks</li>
  <li>June 14, 2019: Second call for workshop papers</li>
  <li>July <s>5</s> <b><span style="color:red">19</span></b>, 2019: End of evaluation phase for the shared tasks</li>
  <li>August <s>19</s> <b><span style="color:red">22</span></b>, 2019: Due date for workshop and shared task papers</li>
  <li>September 16, 2019: Notification of acceptance</li>
  <li>September 30, 2019: Camera-ready papers due</li>
  <li>November 3, 2019: Workshop date</li>
</ul>

All deadlines refer to 11:59pm GMT -12 hours ("anywhere in the world").

<!--a name="speakers"></a>
<div class="page-header">
  <h1>Invited Speakers</h1>
</div>

<ul>
<li><p><h4><a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>: <strong>Commonsense Intelligence: Cracking the Longstanding Challenge in AI</strong></h4></p>
<p>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#yejinabs" aria-expanded="false" aria-controls="collapseExample">
    Abstract
  </button>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#yejinbio" aria-expanded="false" aria-controls="collapseExample">
    Bio
  </button>
</p>
<div class="collapse" id="yejinabs">
  <div class="card card-body">
    <p>Despite considerable advances in deep learning, AI remains to be narrow and brittle. One fundamental limitation comes from its lack of commonsense intelligence: reasoning about everyday situations and events, which in turn, requires knowledge about how the physical and social world works. In this talk, I will share some of our recent efforts that attempt to crack commonsense intelligence. </p>
    <p>
    First, I will introduce ATOMIC, the atlas of everyday commonsense knowledge and reasoning, organized as a graph of 877k if-then rules (e.g., "if X pays Y a compliment, then Y will likely return the compliment”). Next, I will introduce COMET, our deep neural networks that can learn from and generalize beyond the ATOMIC commonsense graph. Finally, I will present RAINBOW, a collection of seven benchmarks that aims to cover a wide spectrum of commonsense intelligence from natural language inference to adductive reasoning to visual commonsense reasoning. I will conclude the talk by discussing major open research questions, including the importance of algorithmic solutions to reduce incidental biases in data that can lead to overestimation of true AI capabilities.</p>
  </div>
</div>
<div class="collapse" id="yejinbio">
  <div class="card card-body">
    Yejin Choi is an associate professor at the Paul G. Allen School of Computer Science & Engineering at the University of Washington and also a senior research manager at AI2  overseeing the project Mosaic. Her research interests include language grounding with vision, physical and social commonsense knowledge, language generation with long-term coherence, conversational AI, and AI for social good. She was a recepient of Borg Early Career Award (BECA) in 2018, among the IEEE’s AI Top 10 to Watch in 2015, a co-recipient of the Marr Prize at ICCV 2013, and a faculty advisor for the Sounding Board team that won the inaugural Alexa Prize Challenge in 2017.  Her work on detecting deceptive reviews, predicting the literary success, and interpreting bias and connotation has been featured by numerous media outlets including NBC News for New York, NPR Radio, New York Times, and Bloomberg Business Week. She received her Ph.D. in Computer Science from Cornell University.
  </div>
</div>
</li>
<li><p><h4><a href="http://www.science.auckland.ac.nz/people/profile/m-witbrock">Michael Witbrock</a>: <strong>Learning to Reason: from Question Answering to Problem Solving 

</strong></h4></p>
<p>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#michaelabs" aria-expanded="false" aria-controls="collapseExample">
    Abstract
  </button>
  <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#michaelbio" aria-expanded="false" aria-controls="collapseExample">
    Bio
  </button>
</p>
<div class="collapse" id="michaelabs">
  <div class="card card-body">
    Recent advances in Machine Learning applied to Natural Language Processing have resulted in systems with quite impressive scores on Question-Answering tests in text and simple visual domains. Similarly, Google Assistant and other similar systems are performing quite well in answering real questions by answer extraction. This progress is real, but it is limited in some important respects: the systems typically have worked by identifying a passage span to serve as an answer; more recently, in "Multi-hop" QA, they have started to work by forming a short linear chain of extracted relations from question to answer.  This falls significantly short of human-problem solving, including question-answering: it does not recursively decompose problems for solution, it does not follow that decomposition to assemble answers, and it does not store and apply salient background knowledge for decomposition, partial solution, or answer composition.  Although it's at the early stage, the aim of our Broad AI Lab is to learn from the far-from-general capabilities of symbolic AI to  extend our reach, especially in problem-solving over text, by applying learning to bridge these current short-falls. In this talk , I'll try to characterise the problem-solving problem and the baseline state-of-the-art, describe some preliminary previous work done with the Learning to Reason team at IBM Research, and sketch a programme towards broader, learning-based, quasi-symbolic AI. We hope this programme will extend the reach of AI-based problem solving, and especially question-answering.
  </div>
</div>
<div class="collapse" id="michaelbio">
  <div class="card card-body">
    Michael Witbrock is a professor of computer science at The University of Auckland, building a research group, the Broad AI Lab, integrating machine learning, reasoning and natural language understanding, with an additional focus on maximizing the near-term benefit of AI to NZ entrepreneurs and business, and more generally achieving the best social and civilizational impacts of increasingly powerful AI.  Prof. Witbrock's PhD is in Computer Science from Carnegie Mellon, and he holds a BSc(Hons) in Psychology from Otago. Before joining the University, he was a Distinguished Research Staff Member and manager of the Reasoning group at IBM T J Watson Research Center in Yorktown Heights, NY.
  </div>
</div>
</li>
</ul-->

<a name="organizers"></a>
<div class="page-header">
  <h1>Organizers</h1>
</div>
<ul class="list-unstyled">
<li><a target="_blank" href="http://allenai.org/team/peterc/">Peter Clark</a>, Allen Institute for AI</li>
<li><a target="_blank" href="http://www.coli.uni-saarland.de/~simono/">Simon Ostermann</a>, Saarland University</li>
<li><a target="_blank" href="http://www.coli.uni-saarland.de/~mroth/">Michael Roth</a>, Saarland University / University of Stuttgart</li>
<li><a target="_blank" href="http://www.cs.jhu.edu/~s.zhang/">Sheng Zhang</a>, Johns Hopkins University</li>
</ul>

<h3>Program Committee<a name="committee" ></a></h3>

<ul class="list-unstyled">
<li><a target="_blank" href="http://researcher.watson.ibm.com/researcher/view.php?person=us-kjbarker">Ken Barker</a>, IBM Research</li>
<li><a target="_blank" href="http://yonatanbisk.com/">Yonatan Bisk</a>, University of Washington</li>
<li><a target="_blank" href="http://www.usna.edu/Users/cs/nchamber/">Nate Chambers</a>, United States Naval Academy</li>
<li><a target="_blank" href="http://www.isi.edu/~hans/">Hans Chalupsky</a>, USC Information Sciences Institute</li>
<li><a target="_blank" href="http://www.uni-saarland.de/lehrstuhl/demberg/members/team.html">Vera Demberg</a>, Saarland University</li>
<li><a target="_blank" href="http://www.cl.uni-heidelberg.de/~frank/">Anette Frank</a>, Heidelberg University</li>
<li><a target="_blank" href="http://people.ict.usc.edu/~gordon/">Andrew S. Gordon</a>, University of Southern California</li>
<li><a target="_blank" href="http://www.cs.vassar.edu/~jgordon/">Jonathan Gordon</a>, Vassar College</li>
<li><a target="_blank" href="http://www.isi.edu/~hobbs/">Jerry Hobbs</a>, USC Information Sciences Institute</li>
<li><a target="_blank" href="http://people.cs.umass.edu/~mccallum/">Andrew McCallum</a>, University of Massachusetts Amherst</li>
<li><a target="_blank" href="http://gerard.demelo.org/">Gerard de Melo</a>, Rutgers University</li>
<li><a target="_blank" href="http://www.mitre.org">Elizabeth Merkhofer</a>, MITRE Corporation</li>
<li><a target="_blank" href="http://www.cl.uni-heidelberg.de/~mihaylov/">Todor Mihaylov</a>, Heidelberg University</li>
<li><a target="_blank" href="http://www.coli.uni-saarland.de/~ashutosh/">Ashutosh Modi</a>, Disney Research</li>
<li><a target="_blank" href="http://people.mpi-inf.mpg.de/~sreyasi/">Sreyasi Nag Chowdhury</a>, Max-Planck-Institut for Informatics</li>
<li><a target="_blank" href="http://homes.cs.washington.edu/~hrashkin/">Hannah Rashkin</a>, University of Washington</li>
<li><a target="_blank" href="http://allenai.org/team/nikett/">Niket Tandon</a>, Allen Institute for AI</li>
<li><a target="_blank" href="http://www.microsoft.com/en-us/research/people/adtrisch/">Adam Trischler</a>, Microsoft Research</li>
<li><a target="_blank" href="http://www.cs.cmu.edu/~bishan/">Bishan Yang</a>, LAER.AI</li>
<li><a target="_blank" href="https://research.nuance.com/author/peter-yeh/">Peter Yeh</a>, Nuance Communications, Inc.</li>
</ul>

<hr>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="bootstrap/js/bootstrap.min.js"></script>
<!--<script src="data/leaderboards/leaderboard1.js"></script>
<script src="data/leaderboards/leaderboard2.js"></script>-->

   <div class="footer">
      <div class="container">
        <p class="text-muted">Website by Michael Roth, powered by <a href="http://www.getbootstrap.com">Bootstrap</a></p>
        <br/>
      </div>
    </div>

</div>

</body>
</html>
